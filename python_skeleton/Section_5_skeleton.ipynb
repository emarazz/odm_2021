{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the mean absolute error:\n",
    "$$\n",
    "MAE = \\frac{1}{N}\\sum_{i=1}^N |y_i-x_i^\\top\\theta|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAE(theta, X, y):\n",
    "    # --------------\n",
    "    # Your Code Here\n",
    "    # --------------\n",
    "    mae = np.mean(np.abs(y - X @ theta))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7.2\n",
    "Implement the problem from Question 7.1 (Use the `GLPK` solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(221, 11)\n(221, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "diabetes = load_diabetes()\n",
    "X, X_test, Y, Y_test = train_test_split(diabetes['data'], \n",
    "                                        np.expand_dims(diabetes['target'], 1), \n",
    "                                        test_size=0.5, random_state=0)\n",
    "\n",
    "# add the bias term\n",
    "X = np.hstack([np.ones([X.shape[0],1]), X])\n",
    "X_test = np.hstack([np.ones([X_test.shape[0],1]), X_test])\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "source": [
    "### Robust Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "N shape: \t221\nk shape: \t165\nD shape: \t11\n"
     ]
    }
   ],
   "source": [
    "# get dimensions\n",
    "N = X.shape[0]\n",
    "k = np.floor(0.75*N).astype('int')\n",
    "D = X.shape[1]\n",
    "\n",
    "print('N shape: \\t{}'.format(N))\n",
    "print('k shape: \\t{}'.format(k))\n",
    "print('D shape: \\t{}'.format(D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define coefficients \n",
    "b = np.vstack((np.ones((N,1)), k))\n",
    "A = np.vstack((np.identity(N), np.ones((1,N))))\n",
    "\n",
    "# define the decision variables\n",
    "theta = cp.Variable((D,1))\n",
    "p = cp.Variable((N+1,1)) # beta = p[:-1], alpha = p[-1]\n",
    "v = cp.Variable((D,1))\n",
    "\n",
    "# define contraints\n",
    "constraints =   [   A.T @ p >= 1/k * (Y - X @ theta),\n",
    "                    A.T @ p >= -1/k * (Y - X @ theta),\n",
    "                    theta <= v,\n",
    "                    -theta <= v,\n",
    "                    p[:-1] >= 0\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best lambda: 0.003393221772\n\u001b[1mValidation Results\u001b[0m\nMAE: 8.886451587972\n\u001b[1mTraining Results\u001b[0m\nMAE: 54.206625371223\n\u001b[1mTest Results\u001b[0m\nMAE: 44.973977912733\n--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# lambdas\n",
    "lambdas = np.logspace(-5.0, -1.0, num=50)\n",
    "best_mae = np.inf # initial value for best_mae\n",
    "\n",
    "for lam in lambdas:\n",
    "    ###\n",
    "    objective = cp.Minimize( b.T @ p + lam * np.ones((D,1)).T @ v )\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    cost = prob.solve(solver=cp.GLPK)\n",
    "    ###\n",
    "\n",
    "    # get z by sorting the absolute error of each sample\n",
    "    ind = np.argsort( np.abs(Y - X @ theta.value), axis=0)[::-1]\n",
    "    z = np.zeros(N)\n",
    "    z[ind[:k]] = 1\n",
    "    z = z.astype(bool)\n",
    "\n",
    "    X_train = X[z]\n",
    "    X_val = X[~z]\n",
    "    Y_train = Y[z]\n",
    "    Y_val = Y[~z]\n",
    "\n",
    "    # Check if the sorted training indices get the same cost as the solver\n",
    "    # print(get_MAE(theta.value, X_train, Y_train) + lam * np.linalg.norm(theta.value, 1))\n",
    "    # print(cost)\n",
    "\n",
    "    mae = get_MAE(theta.value, X_val, Y_val)\n",
    "    if mae < best_mae:\n",
    "        best_z = z\n",
    "        best_mae = mae\n",
    "        best_theta = theta.value\n",
    "        best_lambda = lam\n",
    "\n",
    "    # print(\"Lambda: {:.12f}\".format(lam))\n",
    "    # print(color.BOLD + 'Validation Results' + color.END)\n",
    "    # print('MAE: {:.12f}'.format(get_MAE(theta.value, X_val, Y_val)))\n",
    "    # print(color.BOLD + 'Training Results' + color.END)\n",
    "    # print('MAE: {:.12f}'.format(get_MAE(theta.value, X_train, Y_train)))\n",
    "    # print(color.BOLD + 'Test Results' + color.END)\n",
    "    # print('MAE: {:.12f}'.format(get_MAE(theta.value, X_test, Y_test)))\n",
    "    # print(50*'-')\n",
    "\n",
    "print(\"Best lambda: {:.12f}\".format(best_lambda))\n",
    "print(color.BOLD + 'Validation Results' + color.END)\n",
    "print('MAE: {:.12f}'.format(get_MAE(best_theta, X[~best_z], Y[~best_z])))\n",
    "print(color.BOLD + 'Training Results' + color.END)\n",
    "print('MAE: {:.12f}'.format(get_MAE(best_theta, X[best_z], Y[best_z])))\n",
    "print(color.BOLD + 'Test Results' + color.END)\n",
    "print('MAE: {:.12f}'.format(get_MAE(best_theta, X_test, Y_test)))\n",
    "print(50*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best indices for training set: \n[1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1\n 1 1 0 0 1 0 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 0\n 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 1 1 0 1 1 1 0 1 1 1 1 0\n 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0\n 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 0\n 1 1 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1 1 0 0 1 1 1]\nCardinality of best training set: \n165\nBest theta: \n[[ 1.51471814e+02]\n [-2.30054050e+01]\n [-2.15390319e+02]\n [ 4.58065856e+02]\n [ 2.51256798e+02]\n [ 0.00000000e+00]\n [-4.37811490e+01]\n [-2.26305403e+02]\n [ 1.44068900e-13]\n [ 6.66269812e+02]\n [ 2.20606674e-14]]\nBest lambda: \t0.003393221772\nBest MAE val:\t8.886451587972\n"
     ]
    }
   ],
   "source": [
    "# print best values\n",
    "print('Best indices for training set: \\n{}'.format(best_z.astype(int).T))\n",
    "print('Cardinality of best training set: \\n{}'.format(best_z.sum()))\n",
    "print('Best theta: \\n{}'.format(best_theta))\n",
    "print('Best lambda: \\t{:.12f}'.format(best_lambda))\n",
    "print('Best MAE val:\\t{:.12f}'.format(best_mae))"
   ]
  },
  {
   "source": [
    "### Standard Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(165, 11)\n(165, 1)\n"
     ]
    }
   ],
   "source": [
    "# split the X, Y into  X_train, Y_train and X_val, Y_val\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dimensions for training\n",
    "N = X_train.shape[0]\n",
    "D = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best lambda: 0.007196856730\n\u001b[1mValidation Results\u001b[0m\nMAE: 44.988498062858\n\u001b[1mTraining Results\u001b[0m\nMAE: 45.741476031390\n\u001b[1mTest Results\u001b[0m\nMAE: 46.574314961565\n--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# define the decision variables\n",
    "u = cp.Variable((N,1))\n",
    "v = cp.Variable((D,1))\n",
    "theta = cp.Variable((D,1))\n",
    "\n",
    "# lambdas\n",
    "lambdas = np.logspace(-5.0, -1.0, num=50)\n",
    "best_mae = np.inf # initial value for best_mae\n",
    "\n",
    "for lam in lambdas:\n",
    "    ###\n",
    "    objective = cp.Minimize(1/N * np.ones((N,1)).T @ u + lam * np.ones((D,1)).T @ v)\n",
    "    constraints = [ Y_train - X_train @ theta <= u,\n",
    "                -Y_train + X_train @ theta <= u,\n",
    "                theta <= v,\n",
    "                -theta <= v,\n",
    "    ]\n",
    "\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "    cost = prob.solve(solver=cp.GLPK)\n",
    "\n",
    "    ####   \n",
    "    mae = get_MAE(theta.value, X_val, Y_val)\n",
    "    if mae < best_mae:\n",
    "        best_mae = mae\n",
    "        best_theta = theta.value\n",
    "        best_lambda = lam\n",
    "\n",
    "    # print(\"Lambda: {:.12f}\".format(lam))\n",
    "    # print(color.BOLD + 'Validation Results' + color.END)\n",
    "    # print('MAE: {:.12f}'.format(get_MAE(theta.value, X_val, Y_val)))\n",
    "    # print(color.BOLD + 'Training Results' + color.END)\n",
    "    # print('MAE: {:.12f}'.format(get_MAE(theta.value, X_train, Y_train)))\n",
    "    # print(color.BOLD + 'Test Results' + color.END)\n",
    "    # print('MAE: {:.12f}'.format(get_MAE(theta.value, X_test, Y_test)))\n",
    "    # print(50*'-')\n",
    "\n",
    "print(\"Best lambda: {:.12f}\".format(best_lambda))\n",
    "print(color.BOLD + 'Validation Results' + color.END)\n",
    "print('MAE: {:.12f}'.format(get_MAE(best_theta, X_val, Y_val)))\n",
    "print(color.BOLD + 'Training Results' + color.END)\n",
    "print('MAE: {:.12f}'.format(get_MAE(best_theta, X_train, Y_train)))\n",
    "print(color.BOLD + 'Test Results' + color.END)\n",
    "print('MAE: {:.12f}'.format(get_MAE(best_theta, X_test, Y_test)))\n",
    "print(50*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best theta: \n[[ 141.60326812]\n [   0.        ]\n [-115.76842328]\n [ 300.86042909]\n [ 114.79739473]\n [   0.        ]\n [   0.        ]\n [-166.19218658]\n [   0.        ]\n [ 625.95381683]\n [   0.        ]]\nBest lambda: \t0.007196856730\nBest MAE val:\t44.988498062858\n"
     ]
    }
   ],
   "source": [
    "# print best values\n",
    "print('Best theta: \\n{}'.format(best_theta))\n",
    "print('Best lambda: \\t{:.12f}'.format(best_lambda))\n",
    "print('Best MAE val:\\t{:.12f}'.format(best_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python394jvsc74a57bd07037165d1dc9434c58016773b81034025e81d1427cfde8d6500cf7bb9db0f138",
   "display_name": "Python 3.9.4 64-bit ('odm_2021': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}